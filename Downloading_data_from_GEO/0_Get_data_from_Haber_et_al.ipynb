{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data from paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Find GEO accession Number\n",
    "\n",
    "When data is uploaded to GEO it will be reported in the paper with a GEO accession number. Ctrl + F for GEO will usually get you to the ID needed to download data. For the Haber et al. paper, the accession number is **GSE92332**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Search available data in GEO. \n",
    "\n",
    "Go to the GEO datasets [website](https://www.ncbi.nlm.nih.gov/gds) and put the accession number in the search bar. Scroll through to the bottom will show you all the files that are avaiable. You will notice the raw data is avaiable through SRA (see the link halfway down the page). There are A LOT of datasets affiliated with this study. \n",
    "\n",
    "**Processed data**\n",
    "\n",
    "Let's download the atlas_UMI counts. This is processed data that we will use for downstream analyses. Scroll down to find the \"GSE92332_atlas_UMIcounts.txt.gz\" file. We are going to use web-get again to download the file directly onto the supercomputer. \n",
    "\n",
    "Right-click on the ftp link and select \"Copy Link Address\". \n",
    "\n",
    "Move to a directory on TSCC where you would like the data to land: \n",
    "\n",
    "```mkdir -p ~/scratch/data/haber_intestine/```\n",
    "\n",
    "```cd ~/scratch/data/haber_intestine```\n",
    "\n",
    "Then use wget and paste the link that has been copied into your history:\n",
    "\n",
    "```wget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE92nnn/GSE92332/suppl/GSE92332_atlas_UMIcounts.txt.gz```\n",
    "\n",
    "You will notice the file downloaded in a zipped format. You can unzip with the following command:\n",
    "\n",
    "```gunzip GSE92332_atlas_UMIcounts.txt.gz```\n",
    "\n",
    "\n",
    "**Raw Data**\n",
    "\n",
    "We will process the data from batch1 through the Cellranger pipeline to learn how to generate counts matricies. Since the fastq files are large, we don't want everyone downloading them individually. Instead, this has been done for you and they are located in our shared class directory: \n",
    "\n",
    "    /oasis/tscc/scratch/cshl_2018\n",
    "\n",
    "Instructions on how this was downloaded are here:\n",
    "\n",
    "1) From the GEO page, follow the SRA [link](https://www.ncbi.nlm.nih.gov/sra?term=SRP095033) and find the sequencing results from batch1 located [here](https://www.ncbi.nlm.nih.gov/sra/SRX3361124[accn]).\n",
    "\n",
    "2) Click on the SRA link for that experiment and nagivate to the downloads tab.\n",
    "\n",
    "3) Right-click on the Atlas-bam link to Copy Link Address and use wget to put in a directory on TSCC\n",
    "\n",
    "```cd /directory/for/data/file```\n",
    "    \n",
    "```wget https://sra-download.ncbi.nlm.nih.gov/traces/sra61/SRZ/006985/SRR6985832/Atlas1.bam```\n",
    "\n",
    "4) Convert bam to fastq. The file was uploaded in bam format, but we need fastq for processing. Use this sra command to convert it back. We will use the cellranger command bamtofastq. Documentation [here](https://support.10xgenomics.com/docs/bamtofastq)\n",
    "\n",
    "*Note - this command requires that cellranger has been installed*\n",
    "\n",
    "```bamtofastq --cr11 Atlas1.bam Atlas1```\n",
    "\n",
    "This will create a folder called Atlas1 that contain the fastq files ready for analysis. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2-base",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
