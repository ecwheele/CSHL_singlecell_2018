{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CellRanger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the CellRanger [website](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/what-is-cell-ranger), there is great documentation on how these tools work and how to run them. Here, we will run CellRanger on the first batch of data from the Haber et al. paper. \n",
    "\n",
    "We downloaded data from the first batch of cells, which we learn from the Methods section contained approximately 1500 cells. For a conservative estimate, we will run cellRanger Count with an expected number of cells at 3000. \n",
    "\n",
    "Since this pipeline requires a long time to run, we will submit a job rather than running it interactively like we did with dropseqtools. Take a look at the data download [notebook](URL_here) to get more information on how the fastqs were downloaded. The raw data is located in the class shared folder here: ```/oasis/tscc/scratch/cshl_2018/raw_data_haber/batch1/Atlas1/```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Organize folders for processing**\n",
    "\n",
    "I like to keep track of my projects by making a separate folder for each one with the scripts that I used to generate my results (stored in my home) and a folder for the results (which can be quite large and must be stored in scratch). The code below assumes you have made a softlink into your scratch directory and that softlink exists in your home (Described in detail in notebook [1_Dropseqtools](add_URL_later). \n",
    "\n",
    "```bash\n",
    "mkdir -p ~/projects/haber_batch1/scripts/\n",
    "mkdir -p ~/scratch/projects/haber_batch1/cellranger_results/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a processing script template**\n",
    "\n",
    "To submit a job to the queue (rather than running commands interactively), you write a script and designate the job submission parameters with flags. I like to make a template in my home that I can copy whenever I need to make a new script and just update the amount of compute resources I request. Make a file called ```fake_script.sh``` in your home directory. Add all the lines below that begin with a ```#```. We will go over what each of these mean together, and you can read more about them [here](http://www.sdsc.edu/support/user_guides/tscc-quick-start.html).\n",
    "\n",
    "```bash\n",
    "cd ~\n",
    "vi fake_script.sh\n",
    "i\n",
    "#!/bin/bash\n",
    "#PBS -q home-yeo\n",
    "#PBS -N jobname\n",
    "#PBS -l nodes=1:ppn=1\n",
    "#PBS -l walltime=1:00:00\n",
    "#PBS -o outputfile\n",
    "#PBS -e errorfile\n",
    "\n",
    "#write_command_here\n",
    "\n",
    "esc\n",
    ":wq\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy template and add CellRanger command**\n",
    "\n",
    "Copy your dummy file into the scripts folder that you created for the haber_batch1 data and give it a meaningful name:\n",
    "\n",
    "```bash\n",
    "cp ~/fake_script.sh ~/projects/haber_batch1/scripts/cellranger_count.sh\n",
    "```\n",
    "\n",
    "Edit that script to update the values for all the flags. I will use: \n",
    "```bash\n",
    "#!/bin/bash\n",
    "#PBS -q home-yeo\n",
    "#PBS -N cellranger_count\n",
    "#PBS -l nodes=1:ppn=4\n",
    "#PBS -l walltime=16:00:00\n",
    "#PBS -o cellranger_count.out\n",
    "#PBS -e cellranger_count.err\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read about the CellRanger Count Command**\n",
    "\n",
    "Notice the syntax of my command below. The backslash at the end of the line is used for readability purposes. Usually, when you enter to a new line, that assumes you are entering a new command. However, the ```\\``` tells the computer that what comes on the next line, is actually part of the command on the previous line. Edit your cellranger_count.sh script to include this command below the ```#PBS``` submission parameters. \n",
    "\n",
    "```bash\n",
    "cellranger count \\\n",
    "--id Atlas1_batch1 \\\n",
    "--fastqs ~/cshl_2018/raw_data_haber/batch1/Atlas1/ \\\n",
    "--sample bamtofastq \\\n",
    "--transcriptome ~/software/cellranger-2.1.1/refdata-cellranger-mm10-1.2.0 \\\n",
    "--expect-cells 1500\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submit the job with qsub**\n",
    "\n",
    "By default, cellranger count will put the results in the same folder where the script was run. So first, I will move into scratch where I want the output results. In order for this to work properly when submitting a job to the cluster, I will add the ```cd``` command in the script above ```cellranger count```.\n",
    "\n",
    "```bash\n",
    "cd ~/scratch/projects/haber_batch1/cellranger_results/```\n",
    "\n",
    "When you are happy with your script, you submit the file to the queue with:\n",
    "\n",
    "```bash\n",
    "qsub cellranger_count.sh```\n",
    "\n",
    "Once it has been accepted, you can check on the status with:\n",
    "\n",
    "```bash\n",
    "qstat -u ucsd-trainXY```\n",
    "\n",
    "If you realize you made a mistake, you can delete your job with:\n",
    "\n",
    "```bash\n",
    "qdel JOBID##```\n",
    "\n",
    "For more practice with job submissions, take a look at the [TSCC_job_submission](URL_later) notebook in the tutorials folder.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2-base",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
